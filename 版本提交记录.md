## 版本提交记录（只记录重要更新) 

在history目录里存放着比较重大的历史版本，可以直接运行这些子目录里的run.bat进行演示。

如果想要回到Frog项目的以前任一个提交，可以结合gitk命令和参考本提交记录对每个更新的简介，用git reset命令回复到以前任一个提交版本，例如用:   
git reset --hard ae34b07e 可以转回到2019-08-04提交的分组测试的找食版本。  


### 2018-1-3 
项目启动，主要是文字方面的一些构想。  

### 2019-3-11 1.0.0版, Commit:Go frog go!
开发环境完成，演示第一个人工生命诞生。但是所有Frog脑部为空，因为运动神经元被短路，只能固定向一个方向运动。  
这是第一个发布版，演示了生命的随机进化和优胜劣汰。   
![result1](https://gitee.com/drinkjava2/frog/raw/master/result1.gif)   

### 2019-3-18, Commit:Brain picture!
添加了脑结构图形，用于调试用，可以显示第一个胜出的Frog的脑结构，但是运动神经元依然被短路，只能固定向一个方向运动。  
有了脑结构图，就可以防止所有Frog都被淘汰掉，还不知道问题发生在哪里。可以有针对性地改进进化算法、环境的参数改进。  

### 2019-03-20, 1.0.1版, Commit:Add a button
添加了一个按钮，可以显示、隐藏第一个胜出的Frog的脑结构图，但是运动神经元依然被短路  

### 2019-03-21, 1.0.2版, Commit:I'm hungry
在脑区添加Hungry，删除随机运动的硬编码，改成由Hungry区来驱动，一旦frog能量小于10000,hungry区的所有脑神经元的input区激活，如果这些神经元的输出区位于move区，则作相应的移动。这是一个更随机一点的运动，不再总是固定向一个方向。 

### 2019-03-27, 1.0.3版, Commit:Shrink & Sperm
添加了"卵+精子->受精卵"的模拟，这是为了实现生物多样性。添加了每次添加一批随机神经元，但是只保留激活过的，如果某组神经元从没被用到(激活过)，则有很大的可能不会将这组神经元添加到蛋中(用进废退规则)。

### 2019-03-29, Commit:Rainbow
更正一个小Bug,BrainStructure的zone显示的半径是实际的一半，用彩虹色而不是随机数来表示CellGroup的细胞数量，色彩越靠后表示细胞数越多。

### 2019-04-01, Commit:Cleanup
做一些debug清理,每个Frog不再保留egg的副本，“卵+精子->受精卵”算法改进一下，不能简单两两相加，而是随机取一个精子的cellgroup。

### 2019-04-06, Commit:Windows align
还是做一些清理, 可以自由调整虚拟环境、脑图的显示大小。下面的打算是将mouth、leg、hungry等区移到蛋里去，允许进化，而不是作为Frog的硬编码存在。

### 2019-04-07, Commit:Organ
引入Organ类，将mouth、leg、hungry等作为Organ器官移到蛋里去，而不是作为Frog的硬编码存在，这样架构更清晰，而且便于以后将Organ参与遗传、变异、进化。

### 2019-04-08, Commit:Eye shortcut
添加眼睛，能够看到四个正方向的食物，但是自然选择的结果是眼睛和移动区短路了，眼睛起的作用并不大，因为如果有两个方向同时出现食物，目前青蛙是不能判断的。
下面要考虑逻辑了，也就是思考判断能力（后天条件反射的建立)。

### 2019-04-12, Commit:Random frog
没做大改动，只是将青蛙改成按整个地图随机分布，看起来眼睛的作用就比较明显了，比起随机运动，明显食物被吃掉更多。   
![resut2](https://gitee.com/drinkjava2/frog/raw/master/result2.gif)    

### 2019-05-23, Commit:2 eyes no helps
没做大改动，只是演示添加两个眼睛后，对它的进化没有帮助，到此为此，逐渐看出问题了，没有记忆能力和模式识别能力。目前存在两个比较大的硬编码，导致它不能进一步进化：1.用CellGroup这种硬编码方式，导致在Frog的生存期不能产生记忆功能，而需要多次淘汰，这不符合现实中青蛙从小学到大这样的实际过程，它不需要死很多次。另一个问题是眼睛部分存在硬编码，因此只能起到感光作用，但是不具备根据外在图像进行模式识别能力。所以下面要开始进行非常大的结构改进，。将把CellGroup作为器官引入，但是它的内部细胞是动态生成的，而且不是随机生成的，而是任两个细胞在它的区内活跃就生成新的细胞(将来也可以参与新建细胞)。CellGroup的数量、大小、网格密度（直接影响到神经元生成多少和算法快慢)会参与遗传和进化，快乐和痛苦器官会对新细胞生成的类型有影响。fat参数用来指示它的肥胖度。Fat高的遗传时会保留，并可能变大、变小、内部允行连接数更多、分化成更多CellGroup，但是它的内部连接(新建的细胞)不会参与遗传，这样每个个体都出生时都是一张白纸，虽然也许CellGroup已经进化得很多层很复杂。同一个位置可以存在多个CellGroup,这样由多层大小、位置不同的Layer就同时具备了模式识别和记忆功能，而且这个算法比较简单，很好理解。大范围的Cellgroup可以解释条件反射的形成（两件不相干的事之间形成联系)，小范围的Cellgroup可以解释模式识别（相邻感光细胞同时激活，经过层层处理后，汇总到最上层的某个Cellgroup的激活)。而所有这些CellGroup的形成(结构和层级)都可以用非常简单的"用进废退"规则(Fat值控制遗传、随机变异和适者生存来探索最优解)来最终进化出来。

### 2019-06-13, Commit: Happy & Pain
主要做了一些清理,将所有器官移到单独的类里，删除OrganDesc类。将一些类(如Applicaton移到根包下)移到不同的包下。这个版本是比较大的一个重构，最大的进步是将算法当成一个器官引入，当然，这个版本只存在一个随机连接两端的算法，以后会扩充。
另外，顺手加上了Happy和Pain两个器官，分别对应进食愉快感和痛苦感，后者在靠近边界时激发。观查它的表现，果然不出所料，痛苦感立即生效，有一些Frog移动到边界后就不再前进，而是顺着边界溜下去了，不傻，但是Happy器官没有生效，这也很显然，因为Happy属于进食反射链的一部分，在没有记忆器官（算法）引入之前，是没有途径使用上进食奖励信号的。  
![resut3](https://gitee.com/drinkjava2/frog/raw/master/result3.gif)   

### 2019-06-26, Commit: Back to many connections
找食效率太低，又改回到4.12的用连接数量代替权值这个逻辑，权值这种人为设计的算法居然比不过随机试错，失败。先暂时去掉Pain器官，Pain的加入并没有提高找食效率，必须与感光细胞合用才能知道是哪个方向的边界，下个版本急需引入记忆功能，也就是说要将感光细胞的活跃和痛苦器官的活跃关联起来。  

### 2019-06-28, Commit: New eye & dynamic show brain  
为了更方便青蛙看到边界，又加了个新的眼睛，它是一个可自进化的nxn点阵的眼睛，将来会取代只有四个象素点(但能看得远)的老眼睛。到目前为止，依然还没有进行模式识别和记忆功能的开发。另外脑图可以动态显示了，用一个红圈标记出被动态跟踪显示的青蛙。另外每次运行前打印往生咒，以示对生命的尊重。  

### 2019-07-28, Commit: Trap & Active & Chance
这还是一个常规版本，建立在随机连接、优胜劣汰基础上。主要有以下改动：  
1. 在Env区中间加了一个陷阱区Trap，以增加趣味性，青蛙如果走到陷阱区就死掉，结果自然选择的结果是青蛙会绕开陷阱区。  
2. 青蛙增加一个Active器官，它的作用是一直保持激活，如果有神经元触突位于这个区就会驱动神经元兴奋，这个器官经实践证明比Hungry器官驱动更能提高找食效率。  
3. 青蛙增加一个Chance器官,它的作用是引入随机扰动，打破青蛙有时候围着一个食物打转就是吃不着的死循环。  
从当前这个版本可以看出，实际上青蛙是有一定的记忆能力的，连接就=记忆，只不过没有模式识别能力，以后的工作将以模式识别为重点，基本原理是见note中提到的仿照全息存储原理，在思维区逆向成像。因为逆向成像的限制，以后的版本，所有的器官会被移到脑图的同一侧，不再是随意分布在脑图上了，这将是一个比较明显的改动。当然随机连接这个算法看起来比较有用，以后还是可能保留的。  
以下为运行图像：  
![resut4](https://gitee.com/drinkjava2/frog/raw/master/result4.gif)    

### 2019-08-04, Commit: Screen group test  
引入分屏测试功能，如果青蛙数量多，可以分屏来测试，每屏青蛙的数量可以少到只有1只。  

### 2019-08-05 commit: Seesaw  
有了分屏测试功能后，顺便随手加上了一个青蛙走跷跷板自动平衡的演示，它每次只出场一个青蛙, 每轮包括100场测试，大约跑90多轮半个小时(电脑慢)后，出现了下面的画面：  
![result5](https://gitee.com/drinkjava2/frog/raw/master/result5_seesaw.gif)  
这个版本的目的是为了增加一点趣味性，显得青蛙还是有点"用处"的，省得让人以为这个项目不务正业，只会让青蛙找食。这个版本青蛙的脑结构和找食版的青蛙基本相同，区别只是在于环境不同，也就是说它的表现随着环境而变化，这符合"通用人工智能"的概念，即信号感受器官是统一的(通常是眼睛)，但能根据不同的环境完成不同的任务。走跷跷板演示是最后一个2维脑的版本，今后这个项目将沉寂一段较长时间，今后将致力于将青蛙脑重构为3D金字塔形脑结构(见上文)，因为这个项目的缺点已经很明显，它不具备对2维图像的模式识别能力，用随机试错的方式只能处理非常简单的、信号在视网膜的固定区域出现的图像信号。  
青蛙的找食效率以及走跷跷板平衡的能力都没有优化到顶点，一些构想中的复杂的器官如“与门”、“或门”（不要怀疑大自然能否进化出这些复杂器官)等都没加上，但我认为这不重要，目前最高优先级是先进行3D脑结构建模，让青蛙能具备2维图形的模式识别(和回忆)功能，这个大的架构重构是它能处理复杂图像信息的立足之本，它的图像识别能力和通常的用上千张图片来训练识别一个图片这种工作模式不同，它是一种通用的，可自动分类识别所有图像的模式，更符合动物脑的工作模式，记住并回忆出某个图像(或任意输入信号场景的组合)，可能只需要这种场景重复出现过几次即可，它是一种无外界信号判定，自动分类的识别模式。   

### 2019-09-09 commit: start work on 3d  
开始进行3D脑的实际编程。

### 2019-9-09 到 2019-10-06 之间的6次提交  
主要进行脑框架的显示和字母试别测试环境的搭建，还没开始进行利用器官进行脑细胞播种的工作。这一阶段基本思路是在每一轮的测试过程前半段随机显示ABCD其中的一个字母(即激活视网膜所在的脑区)，并同时激活一个任意脑区。在下半段则只激活这个字母的点阵，然后检测对应的这个脑区是否也会激活，如果激活的话，将会增加青蛙的能量值，让它在生存竟争中胜出，这一步是要完成基本的模式识别功能，框架已搭好，但器官的随机生成还没进行，这一步比较复杂，除了器官的大小位置等参数外，神经元的参数也多，比方说输入、输出光子的方向、正负、数量，能量吸收、释放比例，输入输出阀值、疲劳值、疲劳阀值等，这么多参数要利用随机生成器官的方式来筛选，需要的样本数量多，运行时间会比较长。早期是视网膜和识别区在脑长方体的同一侧，后来的提交改为将视网膜移到左侧，也就是说视觉与识别区(对应耳朵的语音区)在物理上呈90度正交，以方便观察和编程。   

## 版本提交记录（只记录重要更新)

如果想要运行Frog项目的以前版本，可以结合gitk命令和参考本提交记录对每个更新的简介，用git reset命令回复到以前任一个版本，例如用:   
git reset --hard ae34b07e 可以转回到2019-08-04提交的分组测试的找食版本。  



### 2018-1-3 
项目启动，主要是文字方面的一些构想。  

### 2019-3-11 1.0.0版, Commit:Go frog go!
开发环境完成，演示第一个人工生命诞生。但是所有Frog脑部为空，因为运动神经元被短路，只能固定向一个方向运动。  
这是第一个发布版，演示了生命的随机进化和优胜劣汰。   
![result1](https://gitee.com/drinkjava2/frog/raw/master/result1.gif)   

### 2019-3-18, Commit:Brain picture!
添加了脑结构图形，用于调试用，可以显示第一个胜出的Frog的脑结构，但是运动神经元依然被短路，只能固定向一个方向运动。  
有了脑结构图，就可以防止所有Frog都被淘汰掉，还不知道问题发生在哪里。可以有针对性地改进进化算法、环境的参数改进。  

### 2019-03-20, 1.0.1版, Commit:Add a button
添加了一个按钮，可以显示、隐藏第一个胜出的Frog的脑结构图，但是运动神经元依然被短路  

### 2019-03-21, 1.0.2版, Commit:I'm hungry
在脑区添加Hungry，删除随机运动的硬编码，改成由Hungry区来驱动，一旦frog能量小于10000,hungry区的所有脑神经元的input区激活，如果这些神经元的输出区位于move区，则作相应的移动。这是一个更随机一点的运动，不再总是固定向一个方向。 

### 2019-03-27, 1.0.3版, Commit:Shrink & Sperm
添加了"卵+精子->受精卵"的模拟，这是为了实现生物多样性。添加了每次添加一批随机神经元，但是只保留激活过的，如果某组神经元从没被用到(激活过)，则有很大的可能不会将这组神经元添加到蛋中(用进废退规则)。

### 2019-03-29, Commit:Rainbow
更正一个小Bug,BrainStructure的zone显示的半径是实际的一半，用彩虹色而不是随机数来表示CellGroup的细胞数量，色彩越靠后表示细胞数越多。

### 2019-04-01, Commit:Cleanup
做一些debug清理,每个Frog不再保留egg的副本，“卵+精子->受精卵”算法改进一下，不能简单两两相加，而是随机取一个精子的cellgroup。

### 2019-04-06, Commit:Windows align
还是做一些清理, 可以自由调整虚拟环境、脑图的显示大小。下面的打算是将mouth、leg、hungry等区移到蛋里去，允许进化，而不是作为Frog的硬编码存在。

### 2019-04-07, Commit:Organ
引入Organ类，将mouth、leg、hungry等作为Organ器官移到蛋里去，而不是作为Frog的硬编码存在，这样架构更清晰，而且便于以后将Organ参与遗传、变异、进化。

### 2019-04-08, Commit:Eye shortcut
添加眼睛，能够看到四个正方向的食物，但是自然选择的结果是眼睛和移动区短路了，眼睛起的作用并不大，因为如果有两个方向同时出现食物，目前青蛙是不能判断的。
下面要考虑逻辑了，也就是思考判断能力（后天条件反射的建立)。

### 2019-04-12, Commit:Random frog
没做大改动，只是将青蛙改成按整个地图随机分布，看起来眼睛的作用就比较明显了，比起随机运动，明显食物被吃掉更多。   
![resut2](https://gitee.com/drinkjava2/frog/raw/master/result2.gif)    

### 2019-05-23, Commit:2 eyes no helps
没做大改动，只是演示添加两个眼睛后，对它的进化没有帮助，到此为此，逐渐看出问题了，没有记忆能力和模式识别能力。目前存在两个比较大的硬编码，导致它不能进一步进化：1.用CellGroup这种硬编码方式，导致在Frog的生存期不能产生记忆功能，而需要多次淘汰，这不符合现实中青蛙从小学到大这样的实际过程，它不需要死很多次。另一个问题是眼睛部分存在硬编码，因此只能起到感光作用，但是不具备根据外在图像进行模式识别能力。所以下面要开始进行非常大的结构改进，。将把CellGroup作为器官引入，但是它的内部细胞是动态生成的，而且不是随机生成的，而是任两个细胞在它的区内活跃就生成新的细胞(将来也可以参与新建细胞)。CellGroup的数量、大小、网格密度（直接影响到神经元生成多少和算法快慢)会参与遗传和进化，快乐和痛苦器官会对新细胞生成的类型有影响。fat参数用来指示它的肥胖度。Fat高的遗传时会保留，并可能变大、变小、内部允行连接数更多、分化成更多CellGroup，但是它的内部连接(新建的细胞)不会参与遗传，这样每个个体都出生时都是一张白纸，虽然也许CellGroup已经进化得很多层很复杂。同一个位置可以存在多个CellGroup,这样由多层大小、位置不同的Layer就同时具备了模式识别和记忆功能，而且这个算法比较简单，很好理解。大范围的Cellgroup可以解释条件反射的形成（两件不相干的事之间形成联系)，小范围的Cellgroup可以解释模式识别（相邻感光细胞同时激活，经过层层处理后，汇总到最上层的某个Cellgroup的激活)。而所有这些CellGroup的形成(结构和层级)都可以用非常简单的"用进废退"规则(Fat值控制遗传、随机变异和适者生存来探索最优解)来最终进化出来。

### 2019-06-13, Commit: Happy & Pain
主要做了一些清理,将所有器官移到单独的类里，删除OrganDesc类。将一些类(如Applicaton移到根包下)移到不同的包下。这个版本是比较大的一个重构，最大的进步是将算法当成一个器官引入，当然，这个版本只存在一个随机连接两端的算法，以后会扩充。
另外，顺手加上了Happy和Pain两个器官，分别对应进食愉快感和痛苦感，后者在靠近边界时激发。观查它的表现，果然不出所料，痛苦感立即生效，有一些Frog移动到边界后就不再前进，而是顺着边界溜下去了，不傻，但是Happy器官没有生效，这也很显然，因为Happy属于进食反射链的一部分，在没有记忆器官（算法）引入之前，是没有途径使用上进食奖励信号的。  
![resut3](https://gitee.com/drinkjava2/frog/raw/master/result3.gif)   

### 2019-06-26, Commit: Back to many connections
找食效率太低，又改回到4.12的用连接数量代替权值这个逻辑，权值这种人为设计的算法居然比不过随机试错，失败。先暂时去掉Pain器官，Pain的加入并没有提高找食效率，必须与感光细胞合用才能知道是哪个方向的边界，下个版本急需引入记忆功能，也就是说要将感光细胞的活跃和痛苦器官的活跃关联起来。  

### 2019-06-28, Commit: New eye & dynamic show brain  
为了更方便青蛙看到边界，又加了个新的眼睛，它是一个可自进化的nxn点阵的眼睛，将来会取代只有四个象素点(但能看得远)的老眼睛。到目前为止，依然还没有进行模式识别和记忆功能的开发。另外脑图可以动态显示了，用一个红圈标记出被动态跟踪显示的青蛙。另外每次运行前打印往生咒，以示对生命的尊重。  

### 2019-07-28, Commit: Trap & Active & Chance
这还是一个常规版本，建立在随机连接、优胜劣汰基础上。主要有以下改动：  
1. 在Env区中间加了一个陷阱区Trap，以增加趣味性，青蛙如果走到陷阱区就死掉，结果自然选择的结果是青蛙会绕开陷阱区。  
2. 青蛙增加一个Active器官，它的作用是一直保持激活，如果有神经元触突位于这个区就会驱动神经元兴奋，这个器官经实践证明比Hungry器官驱动更能提高找食效率。  
3. 青蛙增加一个Chance器官,它的作用是引入随机扰动，打破青蛙有时候围着一个食物打转就是吃不着的死循环。  
从当前这个版本可以看出，实际上青蛙是有一定的记忆能力的，连接就=记忆，只不过没有模式识别能力，以后的工作将以模式识别为重点，基本原理是见note中提到的仿照全息存储原理，在思维区逆向成像。因为逆向成像的限制，以后的版本，所有的器官会被移到脑图的同一侧，不再是随意分布在脑图上了，这将是一个比较明显的改动。当然随机连接这个算法看起来比较有用，以后还是可能保留的。  
以下为运行图像：  
![resut4](https://gitee.com/drinkjava2/frog/raw/master/result4.gif)    

### 2019-08-04, Commit: Screen group test  
引入分屏测试功能，如果青蛙数量多，可以分屏来测试，每屏青蛙的数量可以少到只有1只。  

### 2019-08-05 commit: Seesaw  
有了分屏测试功能后，顺便随手加上了一个青蛙走跷跷板自动平衡的演示，它每次只出场一个青蛙, 每轮包括100场测试，大约跑90多轮半个小时(电脑慢)后，出现了下面的画面：  
![result5](https://gitee.com/drinkjava2/frog/raw/master/result5_seesaw.gif)  
这个版本的目的是为了增加一点趣味性，显得青蛙还是有点"用处"的，省得让人以为这个项目不务正业，只会让青蛙找食。这个版本青蛙的脑结构和找食版的青蛙基本相同，区别只是在于环境不同，也就是说它的表现随着环境而变化，这符合"通用人工智能"的概念，即信号感受器官是统一的(通常是眼睛)，但能根据不同的环境完成不同的任务。走跷跷板演示是最后一个2维脑的版本，今后这个项目将沉寂一段较长时间，今后将致力于将青蛙脑重构为3D金字塔形脑结构(见上文)，因为这个项目的缺点已经很明显，它不具备对2维图像的模式识别能力，用随机试错的方式只能处理非常简单的、信号在视网膜的固定区域出现的图像信号。  
青蛙的找食效率以及走跷跷板平衡的能力都没有优化到顶点，一些构想中的复杂的器官如“与门”、“或门”（不要怀疑大自然能否进化出这些复杂器官)等都没加上，但我认为这不重要，目前最高优先级是先进行3D脑结构建模，让青蛙能具备2维图形的模式识别(和回忆)功能，这个大的架构重构是它能处理复杂图像信息的立足之本，它的图像识别能力和通常的用上千张图片来训练识别一个图片这种工作模式不同，它是一种通用的，可自动分类识别所有图像的模式，更符合动物脑的工作模式，记住并回忆出某个图像(或任意输入信号场景的组合)，可能只需要这种场景重复出现过几次即可，它是一种无外界信号判定，自动分类的识别模式。   

### 2019-09-09 commit: start work on 3d  
开始进行3D脑的实际编程。

### 2019-9-09 到 2019-10-06 之间的6次提交  
主要进行脑框架的显示和字母试别测试环境的搭建，还没开始进行利用器官进行脑细胞播种的工作。这一阶段基本思路是在每一轮的测试过程前半段随机显示ABCD其中的一个字母(即激活视网膜所在的脑区)，并同时激活一个任意脑区。在下半段则只激活这个字母的点阵，然后检测对应的这个脑区是否也会激活，如果激活的话，将会增加青蛙的能量值，让它在生存竟争中胜出，这一步是要完成基本的模式识别功能，框架已搭好，但器官的随机生成还没进行，这一步比较复杂，除了器官的大小位置等参数外，神经元的参数也多，比方说输入、输出光子的方向、正负、数量，能量吸收、释放比例，输入输出阀值、疲劳值、疲劳阀值等，这么多参数要利用随机生成器官的方式来筛选，需要的样本数量多，运行时间会比较长。早期是视网膜和识别区在脑长方体的同一侧，后来的提交改为将视网膜移到左侧，也就是说视觉与识别区(对应耳朵的语音区)在物理上呈90度正交，以方便观察和编程。  

### 2019-11-03 commit: Two waves
原来最小三维数组的单元格名为Cube,后改为Room，最后又改为cell。器官不再是直接播种Cell了，而是播种Cell或在已存在的Cell里添加行为Action，这个提交模拟了代表视觉信号和听力信号的两个波的传播，下一步的工作是将这两个波关联起来，实现模式识别，基本原理见评论中的果冻比喻，正在编程中。    
另个这个提交添加了t、f、l、r,x五个键来在脑图上选择顶视、前视、左视、右视、斜视这5个方向的视图。       

### 2019-11-11 commit: Done letter test
这是个比较重要的更新，也是切换到3D脑的第一个正式版本更新，它实现了ABCD四个字母的识别。测试时分别用ABCD四个字母，并同时加上一个声音信号，模拟体全息存贮。识别时只激活视网膜区，并且采用变形后的字体，即小一号的斜体字，从显示结果来看，识别效果还是非常好的。另外这个模式识别的工作原理是双向的，如果只单单激活听力区，也会在视网膜区成像的。（如果要做到这点，需要将LetterTester.java中的seeImage和hearSound两行注释互换一下，并去除Cell.java中的59和60两行，这两行代码的作用是阻止光子逆向传播到视网膜上)。  
这个模式识别的原理比较简单，不仅算法简单，而且可能符合人脑的工作模式，它可以进行图像到声音的关联，也可以实现声音到图像成像的逆关联，另外还有两个重要优点:1.它可以同时处理多维的信号，也就是说可以同时处理多个图片、声音等信号。 2.它的训练速度非常快，没有采用什么海量的大数据来进行训练，只要有关联的信号，哪怕信号只出现一两次，它都会自动将它们关联起来。  
有了模式识别，以后的工作就好办了。今后将在这个模式识别基础上进行扩展，进行多参数优化自动生成器官，声音的编码，把小蛇引入到虚拟环境等等一系列更复杂有趣的任务。    

### 2019-11-16 commit: Still done letter test
上次2019-11-11的更新有大bug，有多个字母出现时将不能区分，这次提交更正过来。到此为止，基本完成了模式识别的原理验证过程，即如果字母的象素点与训练图片的重点合越多，则听力区收到的反向红色光子数就越多，这是一个简单、直观的模式识别方法，以后可以通过将声音分成多个小区编码，并统计每个区收到多少反向的光子总数来判断是哪个字母图像输入。原理验证完成后，今后将考虑怎样才能让青蛙自动向这个方向进化，而不是由手工来搭建这个模式识别模型，因为一来参数太多，要减少手工的干预，二来这个原理不光是用到模式识别，其它信号处理（如快感、痛觉信号与行为信号之间的关联)都要用到类似的细胞逻辑。模式识别功能是无法绕过去的，但是一旦原理被证实，以后就可以有意地引导或者说设计青蛙向这个包含这个功能的方向进化。  
另外，这次更新暂停功能加强了，可以在任意时刻暂停，并加上脑图的剖面显示，以方便调试，新增了空格、方向快捷键，现在汇总所有脑图快捷键如下:   
T:顶视  F：前视  L:左视  R:右视  X:斜视  方向键：剖视  空格:暂停  鼠标操作：缩放旋转平移

### 2019-11-26 commit: Chinese test
这次更新用汉字"对酒当歌人生几何"来测试模式识别，优化了一下程序，目前这个图像识别基本没有容错性，图像像素多的会干拢像素少的文字的识别。下面考虑拉大听力信号间隔，以及引入侧抑制等机制（如果一个洞中砸进了光子，但是却和这个洞不同向，有可能产生负值的反向光子，这个负值与角度差有关），这和算法上的侧抑制很象，世界上的道理都是相通的。以后算法上的卷积、深度学习等现成的成果，也可以考虑融入进来，用图形化表示。反过来说，目前以算法进行的神经网络研究，如果借签这个项目的基本思路，把输入输出器官和适应环境进化做为重点，采用遗传淘汰的方式调整算法架构本身，尽量减少人为的设计，最后达到的行为表现可能和这个人工生命项目是一致的。我走图形化是没办法，因为基础差，但是精通算法的人如果明白我的意思，也可能很快做出表现比较复杂的人工生命来，毕竟算法研究已经到了很高的水平了，是现成的。  

### 2019-12-05 commit: add history folder
重整理了一下目录，将当前工作版本放在core目录下, 比较重大的历史版本放在history目录下，以方便初学者直接运行各个历史版本，而不需要使用git reset命令去手工回到以前的历史版本。同时，如果有未完成的子功能研究（如模式识别，见005_letter_test目录)，也可以开一个子目录在history里，以后有时间再去慢慢研究这个子功能。

2019-12-27 在history\003a_legs目录下（依然是2维脑)尝试给青蛙加两条腿，看它能不能自动学会走路。一条腿位于下方，负责左右移动，一条腿位于右侧，负责上下移动，每条腿有抬腿、落腿、转动和相应的感觉细胞。只有当腿落下且转动，而且另一条脚抬起来时青蛙才会位移，具体什么时候抬腿、什么时候转动腿完全由随机数决定。经过一段时间的生存汰淘之后，青蛙会进化出会利用两条腿走路了，但需要的时间非常长，约几个小时之后才达到最高吃食率50%左右，走路风格也比较诡异，是小碎步而不是大踏步。但至少这是青蛙第一次利用两条腿来走路，还是有点意义的，这证明生命进化中就算神经元随机排布，进化出眼睛和腿也是非常简单自然的事。这个实验只给青蛙加了两条腿，但同理如果有四条或更多的腿它应该也是可以随机进化出来的。   
![result7](result7_legs.gif)  
    
### 2020-06-03 加入小蛇Snake进来吃青蛙（未完成）
基本思路是小蛇是有形状的，青蛙要能进化到看到小蛇就跑开，这样就开始正式引入了模式识别
 
### 2020-06-19 正式完成加入小蛇进来，有多处bug改进
蛇只能看到青蛙，青蛙只能看到蛇的图形。并改core目录下项目包名从github到gitee(码云)，负值连线、中间连线引入，用一条斜线来暂时代替蛇的图形，好开始模式识别。

### 2020-06-20 更正SnakeBigEye的bug,并显示为两条线代表蛙的图像（或舌头)，便于简化模式别。设定小蛇只能看到青蛙，青蛙只能看到蛇(严格说是蛇的舌头)。可以看到小蛇会追着青蛙，而青蛙会躲开小蛇，当然也有躲不开被吃掉的。除了引入负值连线用蓝色线条来表示外，技术细节上倒没有什么突破，但这个实验有趣的地方在于它证实了就算是完全随机的排列脑细胞，在长期的优胜劣汰后，生命也会进化出捕食和逃避行为。即然可以进化出捕食和逃避行为，而生命进化又会向越来越复杂的方向进化，所以这个原理可以解释为意识的萌芽了。高等生命的意识，本质上也无非就是大自然随机运动产生的一种复杂现象而已。
![result8](result8_snake.gif)  

2020-06-26 更新readme.md. 下一步的工作将移回到体全息存贮的模式识别，因为青蛙需要这个模式识别功能来更好地分辨出蛇和食物的区别，而体全息存贮个人感觉有很多潜力可挖，它有两个最大的优点:一是可以小样本学习，二是可以同时处理多维的信息输入输出。

2021-01-23 语言的诞生。好不容易，告别漫长的2020，去年出的题目我自己解出来了，下面是答案，运行根目录或core目录下的run.bat，可能看到类似下面的运行画面：  
![result9](result9_earthquake.gif)  
详细解说：这个题目的模拟环境被简化成左右两个区，设定地震发生时（用红框表示）会扣除所有青蛙的能量，但是只有位于左侧的青蛙可以看到地震发生和停止，右区的青蛙不能看到地震发生和停止，但是青蛙有发音器官和听音器官，如果左侧的青蛙发出叫声是可以被右侧的青蛙听到的。看到地震发生、看到地震停止、发出叫声、听到叫声、跳起、落地这6个器官分别对应6种器官并都偶然进化出来(这个无需证明)，这个实验的目的是要验证青蛙会不会在环境逼迫下，在这6种器官对应的脑细胞间形成神经关联。结果可以看到，左侧的青蛙看到地震后，跳在空中（用黄色表示），并发出叫声，然后右侧的青蛙听到叫声后也跳在空中。左侧的青蛙通过叫声信号传递了信息给右侧的青蛙，从而让右侧的青蛙避开了它看不见的地震伤害。这是一个成功的群体进化的演示，它证明了即使是随机生成神经细胞连线，也可以进化出生物的发音-听力功能，也就是说进化出初步的语言功能。  

2021-05-15 细胞分裂的演示    
这是pama_1234做的，他的项目位于这里：[细胞画蛇](https://gitee.com/pama1234/cell-painting-snake), 此更新只更新了readme.md

2021-07-04 依然是模式识别演示  
新增history\005a和005b两个分支目录，分别演示利用改进版的体全息存贮方案和面全息存贮方案来进行模式识别。可以做到将25个任意图形和它对应的声音信号区关联起来。这两个模式的基本原理是基于信号的反向传播，如果一个细胞的两个或多个不同方向同时(或短期内)收到信号，今后只要有一个信号传入，这个细胞将会向其它方向反向发送激活信号。这个模式识别原理非常简单，功能也比较原始，对于变形、扭曲、缩放、缺损的信号识别率很差，但我近期不打算进一步改进它了，而是打算另起炉灶，用三维空间的细胞分裂+遗传算法的模式，试试看能不能让电脑自动演化出具有模式识别功能的模拟生命体，也就是说实现上面发布的任务。  
![result11](result11_letter_test.gif)  

2021-07-04 依然是模式识别演示  
新增history\005a和005b两个分支目录，分别演示利用改进版的体全息存贮方案和面全息存贮方案来进行模式识别。可以做到将25个任意图形和它对应的声音信号区关联起来：  
![result11](result11_letter_test.gif)    
这两个模式的基本原理是基于信号的反向传播，如果一个细胞的两个或多个不同方向同时(或短期内)收到信号，今后只要有一个信号传入，这个细胞将会向其它方向反向发送激活信号。这个模式识别原理非常简单，功能也比较原始，对于变形、扭曲、缩放、缺损的信号识别率很差，但考虑到实现这些功能的复杂性，我近期不打算进一步改进它了，而是打算另起炉灶，用三维空间的细胞分裂+遗传算法的模式，试试看能不能让电脑自动演化出具有简单模式识别功能的模拟生命体，也就是说实现上面发布的任务。    

2021-08-13 演示同时处理多个方向的信号  
位于history\005a1目录下，演示用5个声母和5个韵母的组合来关联到25个图像的识别，这样可以减少声音输入区的数量。它的另一个目的是演示体全息存贮的工作模式可以同时处理多个方向的信号。这个演示分辨率极差，只有约一半的识别率，但我不打算继续改进了。  
![result12](result12_letter_test2.png)    

2021-10-13 失败的细胞分裂尝试  
这次本来想模仿生物细胞的分裂，从一个细胞开始分裂出任意指定的三维形状，并设计了split、goto等基因命令，但是做来做去做不出结果，细胞们就象跳蚤一样乱跑不听使唤，最终还是决定放弃，细胞分裂这个算法太难了。细胞分裂的优点是更“象”生物，而且估计可以利用分形原理缩小基因的长度，基因相当于一种自带循环和条件判断的计算机语言。  
最终生成三维形状这个目标还是借助简单遗传算法完成，通过细胞在相邻位置随机生成，并在基因里记录每个细胞的坐标的方式来实现，基因命令被删得只剩一个了，就是随机生成细胞。  
用遗传算法来生成任意形状，就好象一个画家在画画，但是画什么根本不知道，只知道听从旁边人打分，画的好就打高分，画的不好就打低分，这样一直循环下去，最终画的内容只由打分的人决定。目前速度上还有改进余地，比如让新细胞有更多变异率。  
![result13](result13_frog3d.gif)  

2021-11-08 成功的细胞分裂尝试  
这次的细胞分裂算法采用自顶向下的策略，也就是从单个细胞开始，一个细胞分裂成8个(因为1个正方体切三刀正好是8个小正方体)这种方式来进行。这种方案不是从目标形状的局部开始填充，而是从毛胚、从目标的粗轮廓开始利用遗传算法细化，直到细化出每个细节。这种方案的优点是更接近生物实际，符合“从总体到局部”的正常逻辑，而且有高效的基因压缩存储率，为了说明存储率这点，大家可以看看下图左面这个树结构，猜一猜要存储它最少需要多少个字节?  
![depth_tree](depth_tree.png)  
答案是最少只需要一个整数7就可以表达这个树结构了。说一下原理：首先所有树结构都可以用行号+深度的方式来表达，详见我的博客[基于前序遍历的无递归的树形结构](https://my.oschina.net/drinkjava2/blog/1818631)，获取子树时可以避免递归访问，其次因为采用基因敲除的方式，只需要记录被敲除的树节点的行号和深度就就可以了，最后因为上例固定采用3叉树分形结构，根据行号就可以算出它的深度，所以深度值也可以省略，最后只用一个行号就可以表达这整棵树了。  
下图是这个算法的动画，可以看出它与上次的演示是不同的分裂模式，是先有总体后有细节。项目中实际采用的是8叉树，深度用细胞边长表示:  
![result14](result14_wa3d.gif)  
细胞分裂算法一方面可以利用来生成和优化物理形状(比方虚拟风叶、翅膀、受力结构等形状)，另一方面它和神经网络的形成算法是有共通点的，因为众所周知心脏形状、血管网络、大脑神经网络都是由基因控制细胞分裂出来的。所以以后有可能利用这个算法来自动生成和优化神经网络触突三维空间分布结构。  
顺便说一下，自顶向下的问题是它一旦主分支被误敲除，就不容易补回去，实际的生物例子就是人眼结构还不如章鱼。自然界是用生物的多样化和环境的连续化来保证各种主分支都有尝试。我们电脑模拟要尽量保持环境(任务)的连续化，从低到高一步步走，个别时候考虑结合其它算法给错误的分支打补丁。  

2021-11-26 多参数的细胞分裂  
这次更新放在history\009a_fish3d目录下，只是在上次细胞分裂基础上改进了速度，将三维cell对象数组改为long型数组，节省了对象创建和销毁开销，速度有明显改进。long类型有64位，所以一个细胞可以有64维独立参数，应该够用了。下图是一个6倍速显示的三维鱼分裂生成动图。它一共用到4维参数，分别是细胞的位置和三个不同颜色的细胞色彩参数，每一维分别由各自的细胞分裂算法单独控制：  
![result15](result15_fish3d.gif)  
这个动画的每一帧是细胞分裂到最小不可再分的最终结果，而且是从400个青蛙中生存下来的最佳个体，这就是遗传算法，等价于穷举法。这个16x16x16的大立方体要理解成第一个细胞，只是画的大了而已。以后等有时间可以做1个细胞分成8个，8个变64个的动画，能更好地演示分裂的中间过程。  
细胞分裂研究到此结束，下面要开始生成神经网络空间结构了。我的思路是，脑结构也无非就是三维细胞的空间排布而已，细胞有各种参数，比如触突长度、方向、密度、信号收发阀值、信号强度、信号遗忘曲线等，只要不超过64个参数，就可以用分裂算法来随机试错把神经网络的空间结构给试出来。分裂算法的优点是遵循从主干到细节的生成次序，如果要完成的任务(即外界信号输入输出)也是从简单到复杂，就很可能正好符合这个脑的空间结构生成顺序。  

